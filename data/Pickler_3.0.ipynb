{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "import os\n",
    "import imageio\n",
    "import numpy as np\n",
    "from six.moves import cPickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 256\n",
    "pixel_depth = 255.0\n",
    "num_channels = 3\n",
    "src_dir = 'Pictures'\n",
    "src_labels = \"label.npy\"\n",
    "dst_dir = \"Dataset\"\n",
    "#dataset_shape = (img_per_part, img_size, img_size, num_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(src_dir, dst_dir, src_labels, force=False):\n",
    "    \"\"\"\n",
    "    Function used for splitting tons of photos into smaller compressed batches,\n",
    "    also randomizes data order, and keeps track of proper labels for given data\n",
    "    \"\"\"\n",
    "    if not os.path.exists(dst_dir): #name of saving directory\n",
    "        os.mkdir(dst_dir)\n",
    "    do_pickle(src_dir, dst_dir, src_labels)\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_subdataset(src_folder, src_labels, folder):\n",
    "    \"\"\"\n",
    "    Function loads dataset into memory as one file,\n",
    "    splits label.npy into proper sub parts and saves labels\n",
    "    \"\"\"\n",
    "    #Get files\n",
    "    index = 0\n",
    "    image_files = os.listdir(src_folder)\n",
    "    #initialize array for all images\n",
    "    dataset = np.ndarray(shape = \n",
    "                         (len(image_files),img_size,img_size,num_channels),dtype = np.float32)\n",
    "    labels = np.ndarray(shape = (len(image_files),5))\n",
    "    src_labels_open = np.load(src_labels)\n",
    "    for image in image_files:\n",
    "        image_file = os.path.join(src_folder, image)\n",
    "        name = os.path.splitext(image)\n",
    "        #get unique image_id\n",
    "        num_extracted = int(name[0])\n",
    "    #try:\n",
    "\n",
    "        image_data = (imageio.imread(image_file).astype(float) - pixel_depth/2)/pixel_depth\n",
    "        if image_data.shape != (img_size,img_size,num_channels):\n",
    "            raise Exception('Wrong image shape {}'.format(image_file))\n",
    "        dataset[index,:,:,:] = image_data\n",
    "        labels[index,:] = src_labels_open[num_extracted-1]\n",
    "        index+=1\n",
    "        #print(num_images)\n",
    "   # except(IOError, ValueError) as e:\n",
    "        #print(\"Could not read:\", image_file,\":\",e)\n",
    "        new_label_name = os.path.join(dst_dir, folder+\".npy\")\n",
    "        np.save(new_label_name, labels)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_pickle(src_dir, dst_dir, src_labels, force=False):\n",
    "    \"\"\"\n",
    "    Function compresses dataset from memory, and saves it into part.pickle file\n",
    "    \"\"\"\n",
    "    dataset_names =[]\n",
    "    for folder in os.listdir(src_dir):\n",
    "        pickle_name = folder +'.pickle'\n",
    "        dataset_names.append(pickle_name)\n",
    "        if os.path.exists(pickle_name) and not force:\n",
    "            # You may override by setting force=True.\n",
    "            print('%s already present - Skipping pickling.' % pickle_name)\n",
    "        else:\n",
    "            print('Pickling %s.' % pickle_name)\n",
    "            src_folder = os.path.join(src_dir, folder)\n",
    "            subdataset = make_subdataset(src_folder, src_labels, folder)\n",
    "            try:\n",
    "                dst_pickle_name = os.path.join(dst_dir,pickle_name)\n",
    "                with open(dst_pickle_name, 'wb') as f:\n",
    "                    pickle.dump(subdataset, f, pickle.HIGHEST_PROTOCOL)\n",
    "            except Exception as e:\n",
    "                print('Unable to save data to', set_filename, ':', e)\n",
    "    # For check purpose\n",
    "    return dataset_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling Part1.pickle.\n",
      "Pickling Part10.pickle.\n",
      "Pickling Part100.pickle.\n",
      "Pickling Part101.pickle.\n",
      "Pickling Part102.pickle.\n",
      "Pickling Part103.pickle.\n",
      "Pickling Part104.pickle.\n",
      "Pickling Part105.pickle.\n",
      "Pickling Part106.pickle.\n",
      "Pickling Part107.pickle.\n",
      "Pickling Part108.pickle.\n",
      "Pickling Part109.pickle.\n",
      "Pickling Part11.pickle.\n",
      "Pickling Part110.pickle.\n",
      "Pickling Part111.pickle.\n",
      "Pickling Part112.pickle.\n",
      "Pickling Part113.pickle.\n",
      "Pickling Part114.pickle.\n",
      "Pickling Part115.pickle.\n",
      "Pickling Part116.pickle.\n",
      "Pickling Part117.pickle.\n",
      "Pickling Part118.pickle.\n",
      "Pickling Part119.pickle.\n",
      "Pickling Part12.pickle.\n",
      "Pickling Part120.pickle.\n",
      "Pickling Part121.pickle.\n",
      "Pickling Part122.pickle.\n",
      "Pickling Part123.pickle.\n",
      "Pickling Part124.pickle.\n",
      "Pickling Part125.pickle.\n",
      "Pickling Part13.pickle.\n",
      "Pickling Part14.pickle.\n",
      "Pickling Part15.pickle.\n",
      "Pickling Part16.pickle.\n",
      "Pickling Part17.pickle.\n",
      "Pickling Part18.pickle.\n",
      "Pickling Part19.pickle.\n",
      "Pickling Part2.pickle.\n",
      "Pickling Part20.pickle.\n",
      "Pickling Part21.pickle.\n",
      "Pickling Part22.pickle.\n",
      "Pickling Part23.pickle.\n",
      "Pickling Part24.pickle.\n",
      "Pickling Part25.pickle.\n",
      "Pickling Part26.pickle.\n",
      "Pickling Part27.pickle.\n",
      "Pickling Part28.pickle.\n",
      "Pickling Part29.pickle.\n",
      "Pickling Part3.pickle.\n",
      "Pickling Part30.pickle.\n",
      "Pickling Part31.pickle.\n",
      "Pickling Part32.pickle.\n",
      "Pickling Part33.pickle.\n",
      "Pickling Part34.pickle.\n",
      "Pickling Part35.pickle.\n",
      "Pickling Part36.pickle.\n",
      "Pickling Part37.pickle.\n",
      "Pickling Part38.pickle.\n",
      "Pickling Part39.pickle.\n",
      "Pickling Part4.pickle.\n",
      "Pickling Part40.pickle.\n",
      "Pickling Part41.pickle.\n",
      "Pickling Part42.pickle.\n",
      "Pickling Part43.pickle.\n",
      "Pickling Part44.pickle.\n",
      "Pickling Part45.pickle.\n",
      "Pickling Part46.pickle.\n",
      "Pickling Part47.pickle.\n",
      "Pickling Part48.pickle.\n",
      "Pickling Part49.pickle.\n",
      "Pickling Part5.pickle.\n",
      "Pickling Part50.pickle.\n",
      "Pickling Part51.pickle.\n",
      "Pickling Part52.pickle.\n",
      "Pickling Part53.pickle.\n",
      "Pickling Part54.pickle.\n",
      "Pickling Part55.pickle.\n",
      "Pickling Part56.pickle.\n",
      "Pickling Part57.pickle.\n",
      "Pickling Part58.pickle.\n",
      "Pickling Part59.pickle.\n",
      "Pickling Part6.pickle.\n",
      "Pickling Part60.pickle.\n",
      "Pickling Part61.pickle.\n",
      "Pickling Part62.pickle.\n",
      "Pickling Part63.pickle.\n",
      "Pickling Part64.pickle.\n",
      "Pickling Part65.pickle.\n",
      "Pickling Part66.pickle.\n",
      "Pickling Part67.pickle.\n",
      "Pickling Part68.pickle.\n",
      "Pickling Part69.pickle.\n",
      "Pickling Part7.pickle.\n",
      "Pickling Part70.pickle.\n",
      "Pickling Part71.pickle.\n",
      "Pickling Part72.pickle.\n",
      "Pickling Part73.pickle.\n",
      "Pickling Part74.pickle.\n",
      "Pickling Part75.pickle.\n",
      "Pickling Part76.pickle.\n",
      "Pickling Part77.pickle.\n",
      "Pickling Part78.pickle.\n",
      "Pickling Part79.pickle.\n",
      "Pickling Part8.pickle.\n",
      "Pickling Part80.pickle.\n",
      "Pickling Part81.pickle.\n",
      "Pickling Part82.pickle.\n",
      "Pickling Part83.pickle.\n",
      "Pickling Part84.pickle.\n",
      "Pickling Part85.pickle.\n",
      "Pickling Part86.pickle.\n",
      "Pickling Part87.pickle.\n",
      "Pickling Part88.pickle.\n",
      "Pickling Part89.pickle.\n",
      "Pickling Part9.pickle.\n",
      "Pickling Part90.pickle.\n",
      "Pickling Part91.pickle.\n",
      "Pickling Part92.pickle.\n",
      "Pickling Part93.pickle.\n",
      "Pickling Part94.pickle.\n",
      "Pickling Part95.pickle.\n",
      "Pickling Part96.pickle.\n",
      "Pickling Part97.pickle.\n",
      "Pickling Part98.pickle.\n",
      "Pickling Part99.pickle.\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__' :\n",
    "    main(src_dir, dst_dir, src_labels, force = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obosolete data loader\n",
    "img_data = np.ndarray((img_size,img_size,num_channels),dtype = np.float32) <br>\n",
    "num_extracted = 6000 <br>\n",
    "img_data_arr = np.ndarray(shape =(1,img_size,img_size,num_channels)) <br>\n",
    "print(img_data.shape) <br>\n",
    "img_data_arr[0,0,0,0] = num_extracted <br>\n",
    "img_data_arr[0,:,:,:] = img_data <br>\n",
    "print(img_data_arr.shape) <br>\n",
    "print(img_data_arr[0]) <br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
