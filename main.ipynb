{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "#from Prototype import Model\n",
    "\n",
    "\n",
    "#Rework Loc train routine\n",
    "#USE PLACEHOLDERS WHILE DOING\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\Dataset\n",
      "Found 499 total batches\n"
     ]
    }
   ],
   "source": [
    "#Checking for num of batches\n",
    "path_to_dataset = os.path.join(\"data\",\"Dataset\")\n",
    "print(path_to_dataset)\n",
    "total_num_batches = int((len(os.listdir(path_to_dataset))/2)-1)\n",
    "print(\"Found {0} total batches\".format(total_num_batches))\n",
    "\n",
    "#Parameters of photo                        \n",
    "img_size = 256\n",
    "num_channels = 3\n",
    "\n",
    "#Hyper parameters for network\n",
    "num_classes = 2\n",
    "batch_size = 10\n",
    "total_steps = 2\n",
    "learning_rate_classifier = 1e-4\n",
    "learning_rate_localizer = 1e-4\n",
    "keep_probability = 0.7\n",
    "print_nth_step = 1\n",
    "result_dir = \"./results\"\n",
    "\"\"\"\n",
    "Config variable named params, used for forwarding parameters through\n",
    "whole model\n",
    "\"\"\"\n",
    "#Params used as config file\n",
    "params = {\"result_dir\":result_dir,\n",
    "          \"learning_rate_cl\": learning_rate_classifier,\n",
    "          \"learning_rate_loc\": learning_rate_localizer,\n",
    "          \"img_size\": img_size,\n",
    "          \"num_channels\":num_channels,\n",
    "          \"num_classes\":num_classes,\n",
    "          \"batch_size\":batch_size,\n",
    "          \"total_batches\":total_num_batches,\n",
    "          \"total_steps\":total_steps,\n",
    "          \"keep_probability\":keep_probability,\n",
    "          \"print_nth_step\":print_nth_step}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import functools\n",
    "import os\n",
    "import time\n",
    "from my_load_data import load_dataset_fn \n",
    "\n",
    "def doublewrap(function):\n",
    "    \"\"\"\n",
    "    A decorator of decorator, allowing use of lazy property if no arguments are provided\n",
    "    \"\"\"\n",
    "    @functools.wraps(function)\n",
    "    def decorator(*args, **kwargs):\n",
    "        if len(args) == 1 and len(kwargs) == 0 and callable(args[0]):\n",
    "            return function(args[0])\n",
    "        else:\n",
    "            return lambda wrapee: function(wrapee, *args, **kwargs)\n",
    "    return decorator\n",
    "\n",
    "@doublewrap\n",
    "def define_scope(function, scope = None, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Lazy decorator, optimizes code by loading class Model parts only once to memory\n",
    "    Also its groups tf.Graph, in tensorboard into smaller, more readable parts\n",
    "    \"\"\"    \n",
    "    attribute = '_cache_' + function.__name__\n",
    "    name = scope or function.__name__\n",
    "    \n",
    "    @property\n",
    "    @functools.wraps(function)\n",
    "    def decorator(self):\n",
    "        if not hasattr(self, attribute):\n",
    "            #Sorting Graph by Var_scope\n",
    "            with tf.variable_scope(name, *args, **kwargs):\n",
    "                setattr(self, attribute, function(self))\n",
    "                print(\"Initialized Model.{}\".format(name))\n",
    "        return getattr(self, attribute)\n",
    "    \n",
    "    return decorator\n",
    "\n",
    "\n",
    "class Model(object):\n",
    "    \"\"\"\n",
    "    Model of neural network with all functionalities\n",
    "    \"\"\"\n",
    "    def __init__(self, params, mode=None):\n",
    "        #Variables\n",
    "        self.img_size = params[\"img_size\"]\n",
    "        self.num_channels = params[\"num_channels\"]\n",
    "        self.num_classes = params[\"num_classes\"]\n",
    "        self.lr_cl = params[\"learning_rate_cl\"]\n",
    "        self.lr_loc = params[\"learning_rate_loc\"]\n",
    "        self.keep_prob = params[\"keep_probability\"]\n",
    "        self.total_batches = params[\"total_batches\"]\n",
    "        self.permutation = np.random.permutation(range(params[\"total_batches\"]))\n",
    "        self.write_step = params[\"print_nth_step\"]\n",
    "        self.training = True\n",
    "        self.total_epoch = 0\n",
    "        self.data_iter = 1                       \n",
    "        self.global_step_cl = tf.Variable(0, dtype=tf.int32,\n",
    "               trainable=False, name='global_step')\n",
    "        self.data = tf.placeholder(dtype= tf.float32, shape=[None,256,256,3])\n",
    "        self.target_class = tf.placeholder(dtype=tf.float32, shape=[None,1,1])\n",
    "        self.target_loc = tf.placeholder(dtype = tf.float32, shape=[None,1,1,1,1])\n",
    "        \n",
    "        #Functions returning vars or ops\n",
    "        self.load_data\n",
    "        self.prediction\n",
    "        self.classifier\n",
    "        self.optimize_cl\n",
    "        self.loss_cl\n",
    "        self.localizer\n",
    "        self.optimize_loc\n",
    "        self.loss_loc\n",
    "        \n",
    "        \n",
    "    def get_global_step(self):\n",
    "        return self.global_step_cl.eval()\n",
    "    \n",
    "    @define_scope    \n",
    "    def load_data(self):\n",
    "        \"\"\"\n",
    "        Serve random data each iteration\n",
    "        \"\"\"\n",
    "        with tf.name_scope('Input'):\n",
    "            self.data, self.target_class, self.target_loc = (load_dataset_fn(self.permutation[self.data_iter]))\n",
    "            print(type(self.data))\n",
    "            \n",
    "            \n",
    "            \n",
    "    @define_scope\n",
    "    def prediction(self):\n",
    "        \"\"\"\n",
    "        Main body of neural network, takes data and labels as input,\n",
    "        returns feature map of photo\n",
    "        \"\"\"\n",
    "        #INPUT LAYER\n",
    "        input_layer = tf.reshape(self.data,[-1, self.img_size, self.img_size, self.num_channels])\n",
    "        #1 conv layer\n",
    "        conv1 = tf.layers.conv2d(inputs = self.data, \n",
    "                             filters = 32,\n",
    "                             kernel_size = 5,\n",
    "                             strides = 1,\n",
    "                             padding = \"same\",\n",
    "                             activation = tf.nn.relu)\n",
    "        \n",
    "        #1 pool layer, img size reduced by 1/4\n",
    "        pool1 = tf.layers.max_pooling2d(inputs=conv1,\n",
    "                                        pool_size = 2, \n",
    "                                        strides = 2,\n",
    "                                        padding = \"same\")\n",
    "\n",
    "        #2 conv layer\n",
    "        conv2 = tf.layers.conv2d(inputs = pool1, \n",
    "                             filters = 64,\n",
    "                             kernel_size = 5,\n",
    "                             strides = 1,\n",
    "                             padding = \"same\",\n",
    "                             activation = tf.nn.relu)\n",
    "\n",
    "        #2 pool overal image size reduced totaly by factor of 1/16\n",
    "        pool2 = tf.layers.max_pooling2d(inputs = conv2,\n",
    "                                        pool_size = 2, \n",
    "                                        strides = 2,\n",
    "                                        padding = \"same\")\n",
    "\n",
    "\n",
    "        pool2_flat = tf.reshape(pool2,[-1,(64*64*64)])\n",
    "\n",
    "        dense = tf.layers.dense(inputs = pool2_flat,\n",
    "                            units = 512,\n",
    "                            activation = tf.nn.relu)\n",
    "\n",
    "        dense2 = tf.layers.dense(inputs = dense,\n",
    "                             units = 128,\n",
    "                             activation = tf.nn.relu)\n",
    "        #Droupout layer\n",
    "        self.feature_map = tf.layers.dropout(inputs = dense2, \n",
    "                                    rate = self.keep_prob, \n",
    "                                    training=self.training)\n",
    "\n",
    "        return self.feature_map\n",
    "    \n",
    "        \n",
    "    ##################### CLASSIFIER ###############################\n",
    "    @define_scope\n",
    "    def classifier(self):\n",
    "        \"\"\"\n",
    "        Assigns class to result\n",
    "        \"\"\"\n",
    "        self.logits_cl = tf.layers.dense(inputs = self.prediction,\n",
    "                                 units = self.num_classes,\n",
    "                                 activation = tf.nn.relu)\n",
    "        y_pred = tf.nn.softmax(logits=self.logits_cl)\n",
    "\n",
    "        self.pred_cl = y_pred\n",
    "        return self.pred_cl\n",
    "    \n",
    "    @define_scope\n",
    "    def optimize_cl(self):\n",
    "        \"\"\"\n",
    "        Optimizer of network, call after model.classifier to optimize classifier network\n",
    "        \"\"\"\n",
    "        cross_entropy_cl =  tf.nn.softmax_cross_entropy_with_logits_v2(labels=self.target_class, logits=self.pred_cl)\n",
    "        self.opt_cl = tf.train.AdamOptimizer(self.lr_cl).minimize(cross_entropy_cl)\n",
    "        return self.opt_cl\n",
    "    \n",
    "    @define_scope\n",
    "    def loss_cl(self):\n",
    "        \"\"\"\n",
    "        Function returning loss for classifier\n",
    "        \"\"\"\n",
    "        self.loss_cl_val = tf.losses.softmax_cross_entropy(self.target_class, self.classifier)\n",
    "        return self.loss_cl_val\n",
    "    \n",
    "    def accuracy_cl(self):\n",
    "        \"\"\"\n",
    "        Count the number of right predictions in a batch\n",
    "        \"\"\"\n",
    "        with tf.name_scope('accuracy'):\n",
    "            preds = tf.nn.softmax(self.logits_cl)\n",
    "            correct_preds = tf.equal(tf.argmax(preds, 1), tf.argmax(self.target_class, 1))\n",
    "            self.accuracy_cl_val = tf.reduce_sum(tf.cast(correct_preds, tf.float32))\n",
    "            return self.accuracy_cl_val\n",
    "    \n",
    "    \n",
    "    ###################### LOCALIZER ################################\n",
    "\n",
    "    @define_scope\n",
    "    def localizer(self):\n",
    "        \"\"\"\n",
    "        Function tries to obtain localization of marker on photo\n",
    "        \"\"\"\n",
    "        #Conversion to num_classes output size\n",
    "        self.logits_loc = tf.layers.dense(inputs = self.prediction,\n",
    "                                 units = 4,\n",
    "                                 activation = tf.nn.relu)\n",
    "        \n",
    "        # Softmax output of the neural network\n",
    "        self.pred_loc = tf.nn.softmax(logits=self.logits_loc)\n",
    "        return self.pred_loc\n",
    "    \n",
    "    @define_scope\n",
    "    def optimize_loc(self):\n",
    "        \"\"\"\n",
    "        Optimizes localizer\n",
    "        \"\"\"\n",
    "        cross_entropy_loc =  tf.nn.softmax_cross_entropy_with_logits_v2(labels=self.target_loc, logits=self.pred_loc)\n",
    "        self.opt_loc = tf.train.AdamOptimizer(self.lr_loc).minimize(cross_entropy_loc)\n",
    "        return  self.opt_loc\n",
    "    \n",
    "    @define_scope\n",
    "    def loss_loc(self):\n",
    "        \"\"\"\n",
    "        Returns loss for localizator\n",
    "        \"\"\"\n",
    "        self.loss_loc_val = tf.losses.mean_squared_error(self.target_loc, self.pred_loc)\n",
    "        return  self.loss_loc_val\n",
    "    \n",
    "    \n",
    "    def accuracy_loc(self):\n",
    "        \"\"\"\n",
    "        Count the number of right predictions in a batch\n",
    "        \"\"\"\n",
    "        with tf.name_scope('accuracy'):\n",
    "            preds = tf.nn.softmax(self.logits_loc)\n",
    "            correct_preds = tf.equal(tf.argmax(preds, 1), tf.argmax(self.target_class, 1))\n",
    "            self.accuracy_loc_val = tf.reduce_sum(tf.cast(correct_preds, tf.float32))\n",
    "            return self.accuracy_loc_val\n",
    "    \n",
    "    \n",
    "    def summary(self):\n",
    "        \"\"\"\n",
    "        Create summaries to write them to TensorBoard\n",
    "        \"\"\"\n",
    "        with tf.name_scope('summaries'):\n",
    "            with tf.name_scope('Classifier_summary'):\n",
    "                tf.summary.scalar('loss', self.loss_cl_val)\n",
    "                tf.summary.scalar('accuracy', self.accuracy_cl_val)\n",
    "                tf.summary.histogram('histogram_loss', self.loss_cl_val)\n",
    "                self.summary_op = tf.summary.merge_all()\n",
    "                \n",
    "            return self.summary_op\n",
    "        \n",
    "        \n",
    "        \n",
    "    def build(self):\n",
    "        \"\"\"\n",
    "        Build the computation graph\n",
    "        \"\"\"\n",
    "        self.accuracy_cl()\n",
    "        self.accuracy_loc()\n",
    "        self.summary()\n",
    "        #self.summary_loc()\n",
    "        \n",
    "    \n",
    "    \n",
    "  ####################### TRAINING_OPS #######################################  \n",
    "    \n",
    "    \n",
    "    def train_cl(self, ckpt_dir, sess, init, saver, writer,step, epoch):\n",
    "        \"\"\"\n",
    "        Train one epoch of classifier\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        sess.run(init)\n",
    "        self.training = True\n",
    "        total_loss = 0\n",
    "        num_batches = 0\n",
    "        print(\"called training\")\n",
    "        try: \n",
    "            #train\n",
    "            loss, _, summary = sess.run([self.loss_cl, self.optimize_cl, self.summary_op])\n",
    "            if (step + 1) % self.write_step == 0:\n",
    "                print('Loss at step {0}: {1}'.format(step, loss))\n",
    "                self.data_iter+=1\n",
    "            #save\n",
    "            step+=1\n",
    "            print(\"....\")\n",
    "            writer.add_summary(summary, global_step=step)\n",
    "            total_loss += loss\n",
    "            num_batches += 1\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            pass   \n",
    "        saver.save(sess, ckpt_dir, step)\n",
    "        print('Average loss at epoch {0}: {1}'.format(epoch, total_loss/num_batches))\n",
    "        print('Took: {0} seconds'.format(time.time() - start_time))\n",
    "        return step\n",
    "\n",
    "    \n",
    "\n",
    "    def train_loc(self, ckpt_dir, sess, init, saver, writer, step, epoch):\n",
    "        \"\"\"\n",
    "        Train one epoch of localizer\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        sess.run(init)\n",
    "        self.training = True\n",
    "        total_loss = 0\n",
    "        num_batches = 0\n",
    "        try: \n",
    "            #train\n",
    "            loss, _, summary = sess.run([self.loss_loc, self.optimize_loc, self.summary_op])\n",
    "            if (step + 1) % self.write_step == 0:\n",
    "                print('Loss at step {0}: {1}'.format(step, loss))\n",
    "            #save\n",
    "            writer.add_summary(summary, global_step=step)\n",
    "            step += 1\n",
    "            total_loss += loss\n",
    "            num_batches += 1\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            pass   \n",
    "        saver.save(sess, ckpt_dir, step)\n",
    "        print('Average loss at epoch {0}: {1}'.format(epoch, total_loss/num_batches))\n",
    "        print('Took: {0} seconds'.format(time.time() - start_time))\n",
    "        return step\n",
    "    \n",
    "##### Learning subroutine of network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Learning subroutine of network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_epoch = 10\n",
    "def main(params, mode = None):\n",
    "    result_dir = params[\"result_dir\"]\n",
    "    \n",
    "    #Check for dirs, if not present make them\n",
    "    if not os.path.exists(result_dir):\n",
    "        os.makedirs(result_dir)\n",
    "    ckpt_dir=os.path.join(result_dir,\"ckpt\")\n",
    "    if not os.path.exists(ckpt_dir):\n",
    "        os.makedirs(ckpt_dir)\n",
    "    \n",
    "    graph = tf.Graph()\n",
    "    #Get name as default graph\n",
    "    with graph.as_default():\n",
    "\n",
    "        print(\"Starting Session\")\n",
    "        #Assign name to session, assign it's default graph as graph\n",
    "        with tf.Session(graph=graph) as sess:\n",
    "            \n",
    "            #Creating summary writer \n",
    "            writer = tf.summary.FileWriter(ckpt_dir, graph=graph)\n",
    "                \n",
    "            #Initialization of Model, load all Model functions returning variables\n",
    "            model = Model(params, mode = None)\n",
    "            \n",
    "            #build graph and load summaries\n",
    "            model.build()\n",
    "            \n",
    "            #Assign Initializer\n",
    "            init = tf.global_variables_initializer()\n",
    "            \n",
    "            #Creating save for model session for future saving and restoring model\n",
    "            saver = tf.train.Saver()\n",
    "            \n",
    "            #Loading last checkpoint\n",
    "            ckpt = tf.train.get_checkpoint_state(result_dir)\n",
    "            if ckpt and ckpt.model_checkpoint_path:\n",
    "                #if ckpt found load it and load global step\n",
    "                saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "                print(\"Found checkpoint\")\n",
    "                step = model.get_global_step()   \n",
    "            else: step = 1\n",
    "            \n",
    "                    \n",
    "            #Training\n",
    "            print(\"Starting Training\")\n",
    "           \n",
    "            #for epoch in range(total_epoch):\n",
    "               # step = model.train_cl( ckpt_dir, sess, init, saver, writer,step, epoch)\n",
    "              \n",
    "            \n",
    "        \n",
    "        \n",
    "        print(\"Finnished session\")\n",
    "        #Merge all summaries\n",
    "        #writer.flush()\n",
    "        writer.add_graph(graph)\n",
    "        writer.close()\n",
    "        print(\"Closed summary, work finnished\")\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Session\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "Initialized Model.load_data\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Value passed to parameter 'input' has DataType uint8 not in list of allowed values: float16, bfloat16, float32, float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-2d8ac3cc7b61>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m      \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-e94952358728>\u001b[0m in \u001b[0;36mmain\u001b[1;34m(params, mode)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[1;31m#Initialization of Model, load all Model functions returning variables\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[1;31m#build graph and load summaries\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-1cd0f9628c38>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, params, mode)\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;31m#Functions returning vars or ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize_cl\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-1cd0f9628c38>\u001b[0m in \u001b[0;36mdecorator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[1;31m#Sorting Graph by Var_scope\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m                 \u001b[0msetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattribute\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Initialized Model.{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattribute\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-1cd0f9628c38>\u001b[0m in \u001b[0;36mprediction\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    102\u001b[0m                              \u001b[0mstrides\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m                              \u001b[0mpadding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"same\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m                              activation = tf.nn.relu)\n\u001b[0m\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m         \u001b[1;31m#1 pool layer, img size reduced by 1/4\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python\\envs\\tf-cpu\\lib\\site-packages\\tensorflow\\python\\layers\\convolutional.py\u001b[0m in \u001b[0;36mconv2d\u001b[1;34m(inputs, filters, kernel_size, strides, padding, data_format, dilation_rate, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, trainable, name, reuse)\u001b[0m\n\u001b[0;32m    619\u001b[0m       \u001b[0m_reuse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreuse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m       _scope=name)\n\u001b[1;32m--> 621\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    622\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    623\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python\\envs\\tf-cpu\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    826\u001b[0m       \u001b[0mOutput\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \"\"\"\n\u001b[1;32m--> 828\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m   def _add_inbound_node(self,\n",
      "\u001b[1;32mD:\\Python\\envs\\tf-cpu\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    716\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0min_deferred_mode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 717\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    718\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    719\u001b[0m             raise ValueError('A layer\\'s `call` method should return a Tensor '\n",
      "\u001b[1;32mD:\\Python\\envs\\tf-cpu\\lib\\site-packages\\tensorflow\\python\\layers\\convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convolution_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python\\envs\\tf-cpu\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inp, filter)\u001b[0m\n\u001b[0;32m    866\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    867\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 868\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    869\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python\\envs\\tf-cpu\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inp, filter)\u001b[0m\n\u001b[0;32m    518\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 520\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    521\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python\\envs\\tf-cpu\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inp, filter)\u001b[0m\n\u001b[0;32m    202\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m         name=self.name)\n\u001b[0m\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python\\envs\\tf-cpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[1;34m(input, filter, strides, padding, use_cudnn_on_gpu, data_format, dilations, name)\u001b[0m\n\u001b[0;32m   1040\u001b[0m         \u001b[1;34m\"Conv2D\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1042\u001b[1;33m         data_format=data_format, dilations=dilations, name=name)\n\u001b[0m\u001b[0;32m   1043\u001b[0m     \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python\\envs\\tf-cpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    607\u001b[0m               _SatisfiesTypeConstraint(base_type,\n\u001b[0;32m    608\u001b[0m                                        \u001b[0m_Attr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_arg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_attr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 609\u001b[1;33m                                        param_name=input_name)\n\u001b[0m\u001b[0;32m    610\u001b[0m             \u001b[0mattrs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_attr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattr_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m             \u001b[0minferred_from\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_attr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python\\envs\\tf-cpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_SatisfiesTypeConstraint\u001b[1;34m(dtype, attr_def, param_name)\u001b[0m\n\u001b[0;32m     58\u001b[0m           \u001b[1;34m\"allowed values: %s\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m           (param_name, dtypes.as_dtype(dtype).name,\n\u001b[1;32m---> 60\u001b[1;33m            \", \".join(dtypes.as_dtype(x).name for x in allowed_list)))\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Value passed to parameter 'input' has DataType uint8 not in list of allowed values: float16, bfloat16, float32, float64"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "if __name__ == '__main__':\n",
    "     main(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Paste into conda prompt\n",
    "#   tensorboard --logdir=\"results/\"\n",
    "#   tensorboard --logdir=\"pythondata/MITP Project/results/\"\n",
    "\n",
    "\"\"\"  \n",
    "    def summary_loc(self):\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        with tf.name_scope('summaries'):\n",
    "            with tf.name_scope('Localizer_summary'):\n",
    "                tf.summary.scalar('loss', self.loss_loc_val)\n",
    "                tf.summary.scalar('accuracy', self.accuracy_loc_val)\n",
    "                tf.summary.histogram('histogram_loss', self.loss_loc_val)\n",
    "                self.summary_op_loc = tf.summary.merge_all()\n",
    "        return self.summary_op_loc\n",
    "\"\"\"\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "469px",
    "left": "994px",
    "right": "20px",
    "top": "120px",
    "width": "340px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
